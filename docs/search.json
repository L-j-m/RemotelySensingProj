[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning Diary of CASA0023 Remotely Sensing Cities and Environments 23/24",
    "section": "",
    "text": "Introduction\nHi, my name is Jiaming Li. During my undergraduate study, I was major in Architectural Environment Engineering. Basically it was being an engineer to design the heating and cooling system for a building. We did a lot of energy simulation for buildings, which aimed to further modify the building system to reduce its energy consumption while ensuring its performance.\nIn my current study in Urban Spatial Science course, I found a different perspective to interpret buildings. Now we can see building in a higher level, in which the group of buildings form a city. Therefore, I can improve my understanding on building as a role within an urban area."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Week 1",
    "section": "",
    "text": "Terms\n\nNIR (Near-infrared, which is used to detect vegetation)"
  },
  {
    "objectID": "Week_2.html#week_2",
    "href": "Week_2.html#week_2",
    "title": "2  Week_2",
    "section": "2.1 Week_2",
    "text": "2.1 Week_2"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "9  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Week_2.html#week-2",
    "href": "Week_2.html#week-2",
    "title": "2  Week 2",
    "section": "2.1 Week 2",
    "text": "2.1 Week 2"
  },
  {
    "objectID": "Week_3.html",
    "href": "Week_3.html",
    "title": "3  Week 3",
    "section": "",
    "text": "4 Week 3"
  },
  {
    "objectID": "Week_2.html#the-xaringan-presentation",
    "href": "Week_2.html#the-xaringan-presentation",
    "title": "2  Week 2",
    "section": "2.1 The Xaringan presentation",
    "text": "2.1 The Xaringan presentation"
  },
  {
    "objectID": "Week_3.html#corrections",
    "href": "Week_3.html#corrections",
    "title": "3  Week 3",
    "section": "3.1 Corrections",
    "text": "3.1 Corrections\nThere are four types of corrections:\n\nGeometric correction\nAtmospheric correction\nOrthorectification / Topographic correction\nRadiometric correction"
  },
  {
    "objectID": "Week_3.html#terms",
    "href": "Week_3.html#terms",
    "title": "3  Data Enhancement",
    "section": "Terms",
    "text": "Terms\n\n.MTL file: store the data of Earth-sun distance.\nNDVI (Normalised Difference Vegetation Index).\nNDMI (Normalized Difference Moisture Index)."
  },
  {
    "objectID": "Week_3.html#data-enhancement",
    "href": "Week_3.html#data-enhancement",
    "title": "3  Week 3",
    "section": "3.2 Data enhancement",
    "text": "3.2 Data enhancement\nTasseled Cap function -&gt; Principal Component Analysis (PCA)\nThe PCA is a process that transform the data which has reduced its dimensionality. This is to highlight certain feature of an image.\n\n3.2.1"
  },
  {
    "objectID": "intro.html#remote-sensing-data",
    "href": "intro.html#remote-sensing-data",
    "title": "1  Week 1",
    "section": "1.1 Remote sensing data",
    "text": "1.1 Remote sensing data\n\nSentinel:\nCollected by European Space Agency (ESA)\nLandsat\nCollected by United States Geological Survey (USGS) and NASA.\n\nWhen doing the comparison of Sentinel and Landsat dataset, the image from Sentinel should be upscaled as the resolution of Sentinel RGB bands are 10 meter while the RGB bands from Landsat are 30 meter. When looking at the natural colors of images, we’ll use B2, B3, and B4 in blue, green, and red pipes, therefore, the those bands should be upscaled from 10 meter to 30 meter.\nThe color of an image is formed by electromegnetic, or, it is a representation of information of targets on the Earth surface. In this case, how electromegnetic is expressed by color would be essential to understand the targets on the Earth surface, and we can change the math expression of the bands to make the color have different meaning.\nThe component of target within a pixel can be analyzed from Spectrum View, in which x axis is the Wavelength (nm) of bands, y axis is the percentage of reflectance (?). The table below shows the wavelength of each band:\n\n\n\nBand\nWavelength (nm)\nDescription\n\n\n\n\nB1\n443\nUltra Blue (Coastal and Aerosol)\n\n\nB2\n490\nBlue\n\n\nB3\n560\nGreen\n\n\nB4\n665\nRed\n\n\nB5 - B8, B8a\n705 - 865\nVisible & Near Infrared (VNIR)\n\n\nB9 - B12\n940 - 2190\nShort Wave Infrared (SWIR)"
  },
  {
    "objectID": "Week_2.html#reflection",
    "href": "Week_2.html#reflection",
    "title": "2  Week 2",
    "section": "2.2 Reflection",
    "text": "2.2 Reflection"
  },
  {
    "objectID": "intro.html#summary",
    "href": "intro.html#summary",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\nRemote sensing, or called Earth Observation (EO), refers to obtain information from a distance. Generally, satellites or drones are typical remote sensors, which are used to acquiring data of Earth ground.\nAn advantage of remote sensing data is that it has large amount of data size, which update frequently (around every day to every 16 days). Therefore, it would be suitable for timely analysis the variation of city or building, and they could be observed in a longer time (years or decades).\n\n1.1.1 Remote sensing data\n\nSentinel:\nCollected by European Space Agency (ESA)\nLandsat\nCollected by United States Geological Survey (USGS) and NASA.\n\nFormat: generally raster.\nResolutions: spatial (pixels), spectral (bands), temporal (days, years), radiometric (the ability of detecting the radiation difference. unit: 8 bit, 11 bit).\nThe sensor detecting Earth ground relies on electromagnetic radiation, and a key character of it is the wavelength (λ). It would determine the ability of sensors that penetrate through clouds or ground layers. For instance, for longer wavelength, they are less likely to be scattered by clouds, thus they’re more likely to obtain data in a cloudy weather.\nIn terms of the data, generally they are images. The color of an image data is formed by electromagnetic, or, it is a representation of information of targets on the Earth surface. In this case, how electromagnetic is expressed by color would be essential to understand the targets on the Earth surface, and we can change the math expression of the bands to make the color have different meaning.\n\n\n1.1.2 Interacting with ground surface\n\nBidirectional Reflectance Distribution Function (BRDF): It’s a function that describes the ratio of the reflectance light that viewer could receive and the source of light that illuminates the object.\n\n\n\n\nSchematic plot of reflectance, the amount of reflected light would be less or equal to the incoming light (Wynn, 2000)\n\n\nThe two types below is more about SAR data.\n\nPolarization: This refers to the deflection of signals. There are two plane of electromagnetic signal: horizontal and vertical. When the signal is polarized, the direction of electromagnetic oscillation may change.\nFluoresence: The wavelength of radiation would change after arriving the target.\n\n\n\n1.1.3 Practical Result\nFor the practical, I selected five points for analysis:\n\n\n\nYellow: bare plane; green: forest; red: lower urban; pink: higher urban; brown (a small dot to the right in the middle): grass\n\n\nThe spectral signatures could be generated by selecting point of interested in the map, and it could be plotted by R. The figures below show the line graph of bands:\n\n\n\n\n\nThe bands have been renamed, and the wavelength of each band should be checked (see here). As every landscape has its own spectral signature, it could be used to determine the components within the POI. However, due to limit resolution and number of points, this result might not quite precise to detect the landscapes. For example, the variance of high_urban area is large, which means it contain other components addition to buildings."
  },
  {
    "objectID": "intro.html#application",
    "href": "intro.html#application",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\nNavalgund, Jayaraman, & Roy (2007) suggested that remote sensing technology is applied in agriculture, water resources management, ocean observation, environmental assessment and disaster monitoring. It’s generally an implementation in large area. For example, it could be used to estimate crop acreage and yield, and some more detail observation could be achieve, such as drought and flooding, as the increase in sensor resolution (Wójtowicz, Wójtowicz, & Piekarczyk, 2016). Unmanned Aerial Vehicle (UAV) can provide a ultra-high-resolution data (less than 10 cm), but it’s lack of land-cover classification compared with satellite observation data (Yao, Qin, & Chen, 2019). Therefore, on the physical level, it’s difficult to balance between high observing resolution and the abundance of information. However, it might be possible through software engineering, which gathers remote sensing data from different sources. To achieve that, Rathore et al. (2015) suggested an analytical architecture that process real-time big-data for remote sensing."
  },
  {
    "objectID": "intro.html#reflection",
    "href": "intro.html#reflection",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nIn this week, the basic knowledge frame of remote sensing was introduced. What I found interested was the way that remote sensor works. Before, I though the sensors would work as camera, which capture information by taking picture. But in effect, the electromagnetic that emit and receive by the sensors is actually important. It is the bands that make up the message. Especially, in terms of the application of SAR sensors, it could largely ignore the weather condition, and constantly observing the Earth ground.\n\n1.3.1 Notes\nWhen doing the comparison of Sentinel and Landsat data set, the image from Sentinel should be up-scaled as the resolution of Sentinel RGB bands are 10 meter while the RGB bands from Landsat are 30 meter. When looking at the natural colors of images, we’ll use B2, B3, and B4 in blue, green, and red pipes, therefore, the those bands should be up-scaled from 10 meter to 30 meter.\nThe component of target within a pixel can be analyzed from Spectrum View (in SNAP), in which x axis is the Wavelength (nm) of bands, y axis is the percentage of reflectance."
  },
  {
    "objectID": "Week_3.html#summary",
    "href": "Week_3.html#summary",
    "title": "3  Data Enhancement",
    "section": "3.1 Summary",
    "text": "3.1 Summary\nThe process of remote sensing based on three essential components: light sources (illuminentes), target (Earth ground), and sensors. The light source could be the same as the sensors (active sensor, SAR).\nTo store the information of targets, the radiance would be “translated” into the Digital Number (DN), which is the raw data of ground information. Those raw data would be combined with theirs location, and then it could form the map. (source: OpenLibrary)\n\n3.1.1 Radiance & Reflectance\nThe radiance is used to describe the light that received by sensors, while reflectance relates to the properties of the targets.\n\nRadiance: how much light the sensor can receive (the radiation leaving the Earth).\nReflectance: the ratio of light leaving a target to the light striking the target.\n\nBOA (Bottom of Atmosphere) reflectance: reflected by the target on Earth surface.\nTOA (Top of Atmosphere) reflectance: regard atm as the target, can be converted from TOA radiance (path radiance).\n\n\n\n\n3.1.2 Correction\nThe accuracy of remote sensing data may have its limit due to several reasons, such as the relative position between satellites and ground (view angle), atmospheric scattering, property of instruments. Therefore, we need to do the corrections before analyzing the data.\nThere are four types of corrections:\n\nGeometric correction\nAtmospheric correction\nOrthorectification / Topographic correction\nRadiometric correction\n\nA useful atmospheric correction called Dark Object Subtraction (DOS). The basic assumption in the algorithm is that the darkest pixel in the image should not have any light. Thus, any reflectance from this pixel should caused by the atmospheric. As those light doesn’t achieve the ground but being reflected to the sensors. Therefore, all pixel should subtract this impact.\n\n\n3.1.3 Data enhancement\nTasseled Cap function -&gt; Principal Component Analysis (PCA)\nThe PCA is a process that transform the data which has reduced its dimensionality. This is to highlight certain feature of an image.\n\n\n3.1.4 Data Pre-process\nA problem of remote sensing data is that the area of one image may not cover the entire study area, as the satellites are moving relative to the ground and scan the land square by square. The date of different data square would be varied. Therefore, to obtain the ground information of whole study area, the data should be accessed over a period of time. Then, the images should be merged together to form the targeted area.\nThe quality of remote sensing data are tired, which would be checked in here.\nIn this study, the ground information of Cape Town would be explored.\n\n\n\nA screen shot on USGS website when capturing the data in Cape Town\n\n\nAs shown in the figure, two square of remote sensing data would be used. There is an overlapped area between the two data set, and it should be eliminated in the merging process (called Mosaicking in remote sensing). The merging process is basically calculate the average value from different data square for the overlapped area. As the study area may not precisely locate within the square in the selected time period, this is a compromise for the provided data.\n\n\n3.1.5 Information Enhancement\nThe remote sensing data contains lots of information, selecting and combining those information is important for study what we focus on. Using Normalised Difference Vegetation Index (NDVI) as an example to show how the combination of bands could generate useful information.\nThe equation of NDVI is: NDVI = (NIR - Red) / (NIR + Red)\nIn Landsat data set, it is: NDVI = (B5 - B4) / (B5 + B4)\n\n\n\nThe result of NVDI plot in the targeted region\n\n\nThe value of NVDI indicate the component or state of the plants. If the NVDI &gt; 0.2, it represents the area with leaf; if the NVDI &gt; 0.6, it represents healthier leaf.\n\n\n\n\n\nAccording to the division, the leaf condition could be detected in Cape Town:\n\n\n\nNVDI &gt; 0.2\n\n\n\n\n\nNVDI &gt; 0.6\n\n\nThe figures show that few health leaf in the Cape Town, probably because the time period of the data is around May, when it’s close to winter in the Southern Hemisphere."
  },
  {
    "objectID": "Week_3.html#application",
    "href": "Week_3.html#application",
    "title": "3  Data Enhancement",
    "section": "3.2 Application",
    "text": "3.2 Application\nPCA is a useful tool to reduce the noise for remote sensing data. Uddin, Mamun, & Hossain (2021) concluded that PCA-based feature reduction could be efficient for hyperspectral image (HSI) classification, and they assessed the performance by using a Support Vector Machine (SVM) classifier. Since HSI contains more bands than normal color images, reduce uneccessary information would enhance the accuracy of classification.\n\n\n\nThe workflow for PCA-based HSI classification (Uddin, Mamun, & Hossain, 2021)\n\n\nHowever, only two dataset they used for analysis might not be sufficient, as particular place might has its occasionality in terms of atmosphere condition, surface structure, etc."
  },
  {
    "objectID": "Week_3.html#reflection",
    "href": "Week_3.html#reflection",
    "title": "3  Data Enhancement",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nThere are other ways to process and enhance the remote sensing data, and substantially they are used to reduce the amount of data.\nFor example, using moving windows to filter the data, essentially, it’s to increase the contrast of the image while reducing the noise pixels.\nComparing to directly process the data, Principle Component Analysis (PCA) is a more advanced, or abstract technique that replace the variables by their correlations. Then, using the variation in each fitting line, it could calculate the importance of each correlation. Essentially, PCA could be used to reduce the dimension of data. I found Kim (2022) explained the PCA very well. He suggested that the process of PCA likes an orthorectification correction, and those dimensions in which data has not variation should be filtered out.\n\n\n\nThe data has few variation in Z axis, therefore, Z dimension could be subtracted"
  },
  {
    "objectID": "GEE.html",
    "href": "GEE.html",
    "title": "5  Week 5 GEE",
    "section": "",
    "text": "6 Google Earth Engine"
  },
  {
    "objectID": "GEE.html#summary",
    "href": "GEE.html#summary",
    "title": "5  Google Earth Engine",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nThe Google Earth Engine (GEE) is an online geospatial platform that allow geoanalyst to access Google server to do the spatial analysis.\nAs the platform has a large remote sensing database, our computer doesn’t have to actually load the data when running the code, instead, it could call the data as a proxy in the code script, which save the room in the local computer.\n\n5.1.1 Object\nThe object in GEE is like the data structures in other programming language. Each object belongs to specific class, and each class has its specific functions (methods).\n\n\n5.1.2 Data process in GEE\nGEE can filter specific image from image collections by its date, and clip the map to generate targeted study area. It can also do texture analysis and PCA.\n\n\n5.1.3 PCA in GEE\nThe result of PCA in GEE illustrate that there are two main geographic components in this region, as the first two PCs added up to around 93% of variance which is used to describe the importance of the geographical data.\n\n\n\nThe PCA result in Delhi\n\n\n\n\n\nThe percentage of variance of each PC"
  },
  {
    "objectID": "GEE.html#application",
    "href": "GEE.html#application",
    "title": "5  Google Earth Engine",
    "section": "5.2 Application",
    "text": "5.2 Application\nGoogle Earth Engine (GEE) is widely used in the analysis of land cover, water resource, vegetation cover, etc (Zhao et al., 2021). It a powerful online platform that combines big data and time-series analysis with geospatial study. As large amount of data could be directly called as image and feature collection on the GEE, 90% of researchers utilize the remote sensing datasets in their study, while 10% of scholars would use existed product for their analysis, and an overall accuracy of 70% to 99% was achieved (Tamiminia et al, 2020).\nWhile GEE is applied in many Earth observation topics, here are two examples of its applications.\n\n5.2.1 Collect Earth\nCollect Earth is open-source software for monitoring land use variation, which is developed by the Food and Agriculture Organization of the United Nations (FAO) (Bey et al., 2016). It is based on a combination of Google Earth, Bing Maps and GEE. Users can observe land use in Google Earth, and they can implement more analysis with a longer time range and high image resolution in conjunction with GEE and Bing Maps (Collect Earth).\n\n\n5.2.2 Global Water Watch\nAs one of a ready-to-use product basd on GEE, this project allows globally access, which aims to share the information of small and median water reservoirs. They argued that water resource is crucial from living, but more than half of population in the world are in the countries that share river basin with other countries. This means, the competition of water use between countries would potentially increase the conflict, therefore it is more important to break information barriers and co-manage the water resource (source: GWW).\nThe screen shot shows the the app they created in GEE (access from here):\n\n\n\n\n\nI randomly selected a water reservoir in Riyadh, Saudi Arabia, and the app can show the historical variation of surface water. However, since there are many layers in this GEE app, the loading speed would be slow. It’s more convenient to access their website to obtain water resource information."
  },
  {
    "objectID": "GEE.html#reflection",
    "href": "GEE.html#reflection",
    "title": "5  Google Earth Engine",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\n\n5.3.1 Loop vs. Map\nSince GEE use JavaScript to edit the code, using map function to do the iteration could be more efficient in terms of code writing and code running. By using map, we don’t have to count the number of objects (images) in the collection, but it will apply the function to each object. Crites (2019) argued that it’s called “true iteration”, though I don’t think so, as both function could achieve the same result. However, using map can actually make the code cleaner."
  },
  {
    "objectID": "Week_4.html",
    "href": "Week_4.html",
    "title": "4  Week_4 Policy",
    "section": "",
    "text": "5 Policy"
  },
  {
    "objectID": "Week_4.html#summary",
    "href": "Week_4.html#summary",
    "title": "4  Policy",
    "section": "4.1 Summary",
    "text": "4.1 Summary\n\n4.1.1 Sustainability challenge in Shanghai\nAs the main place of economic and production activities, cities are responsible for the most part of carbon emission. Shanghai is one of the biggest cities in China, gathering dense population and growing its economic rapidly, which makes a high energy demand. Though the energy intensity has already declined by the optimizition of industry structure, the CO2 emission is still higher than some other provinces (Gao and Pan, 2022). There are two ways of carbon neutrality: one is to reduce the source emission, another is to capture and absorb the CO2. Carbon sink is the term that describes CO2 absorption. Generally, there are green and blue carbon sink, which refer to forest and sea. The CO2 could be absorbed by the plants in the photosynthesis process, and therefore it reduce carbon in the air.\nChongming district is the world largest alluvial island, and it occupies around 20% area of Shanghai (1411/6340 km2). The forest area and theirs ability of carbon sink is supposed to balance the carbon emission within the island, however, though policy has restricted the construction development, local implementation didn’t fully comply with the policy. The construction land, which converted from cropland, achieved 20% in 2013 while the restriction was 13% in 2020 (Guo et al., 2017). This expansion highly impact the carbon cycle balance.\n\n\n\nThe Chongming Island (Guo et al., 2017)\n\n\nIn effect, relevant policies have been released in terms of emission reduction, but challenges still exist in the practical level. The balance between abatement and economic development is generally not easy, as the performance of local government is currently measured by local economy. Therefore, it’s necessary to establish new criteria of assessment align with the ecodevelopment.\n\n\n4.1.2 Relevant policies\nIn the international level, the Paris Agreement was established by the UN Framework Convention on Climate Change in 2016. This conference asked participating countries to update their Nationally Determined Contributions (NDCs) every few years. This NDC is the environmental protection object againsts global warming in the national level. China’s latest version of NDC had been updated in 2021, and the key points are:\n\nlower CO2 emission per GDP by over 65% from 2005 level.\nincrease the share of non-fossil fuels in primary energy consumption to around 25%,\nincrease the forest stock volume by 6 billion m3 from the 2005 level,\nbring its total installed capacity of wind and solar power to over 1.2 billion kW.\n\nIn terms of the domestic policy, Hepburn et al. (2021) summarized the specific measure that China would implement during the 14th Five-year period (2021-2025) for achieving carbon neutrality goal by 2060. There is a “1 + N” policy system. The “1” refers to two documents (The Guideline and the Action Plan), which are general policies. The “N” refers to supportive and implementation plan in specific fields and industries (i.e.).\nIn local level, Shanghai government has released local Implementation Plan in 2022, which aligns with the national level policy requirement. Specific local industries were considered in the local policy."
  },
  {
    "objectID": "Week_4.html#application",
    "href": "Week_4.html#application",
    "title": "4  Policy",
    "section": "4.2 Application",
    "text": "4.2 Application\nIn terms of promoting sustainable development in Shanghai, remote sensing could be useful in detecting two aspects: emission detection and carbon sink.\n\nEmissions detection\n\nTo spatialized the carbon emission, night time light (NTL) remote sensing data could be used to located the place with potentially high pollution. It’s needed to combine the map with other economic and energy consumption data, which helps to understand the hidden reason of emission (Gao et al., 2023). In this case, the remote sensing data is one of the indicators used to measure the carbon emission.\nSome satellites are typically used for CO2 detection (GOSAT, OCO-2, and TanSat). However, the current satellites have limit resolution to locate the exact emission source (Wu et al., 2023).\n\nCarbon sink measurement\n\nAs called green carbon sink, the structure of forest, i.e. species of trees, age of trees, is highly related to its ability of capturing carbon (Zhang et al., 2022). Using remote sensing could obtain the information of carbon sink quicker and more accurate than conventional filed team survey."
  },
  {
    "objectID": "Week_4.html#reflection",
    "href": "Week_4.html#reflection",
    "title": "4  Policy",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nThe application of remote sensing is basically monitoring the carbon emission source and carbon sink area. It can help to identify the area with high carbon emission, and the carbon storage potential in certain area, such as wetland, forest. Technically, the remote sensing could not actually reduce the carbon emission, but it could play a role as a verification tool which provides the evidence that the carbon emission is reduced. In practice, the information from bottom-up should be combined with the observation data from remotely sensing, which is top-down, could help policy maker to verify the result of work.\nThe advantage of using observation data from remote sensing satellite is its efficiency. Satellites have wide vision that could cover thousands square kilometers area while having less than 1 meter resolution, and the installation of local sensor would be not necessary."
  },
  {
    "objectID": "Week_4.html#reference",
    "href": "Week_4.html#reference",
    "title": "4  Policy",
    "section": "4.4 Reference",
    "text": "4.4 Reference\nHepburn, C., Qi, Y., Stern, N., Ward, B., Xie, C. and Zenghelis, D., 2021. Towards carbon neutrality and China’s 14th Five-Year Plan: Clean energy transition, sustainable urban development, and investment priorities. Environmental Science and Ecotechnology, 8, p.100130.\nGao, F., Wu, J., Xiao, J., Li, X., Liao, S. and Chen, W., 2023. Spatially explicit carbon emissions by remote sensing and social sensing. Environmental Research, 221, p.115257.\nGao, J. and Pan, L., 2022. A System Dynamic Analysis of Urban Development Paths under Carbon Peaking and Carbon Neutrality Targets: A Case Study of Shanghai. Sustainability, 14(22), p.15045.\nGuo, R., Zhao, Y., Shi, Y., Li, F., Hu, J. and Yang, H., 2017. Low carbon development and local sustainability from a carbon balance perspective. Resources, Conservation and Recycling, 122, pp.270-279.\nWu, K., Yang, D., Liu, Y., Cai, Z., Zhou, M., Feng, L. and Palmer, P.I., 2023. Evaluating the Ability of the Pre-Launch TanSat-2 Satellite to Quantify Urban CO2 Emissions. Remote Sensing, 15(20), p.4904.\nZhang, Y., Lu, D., Jiang, X., Li, Y. and Li, D., 2022. Forest structure simulation of eucalyptus plantation using remote-sensing-based forest age data and 3-pg model. Remote Sensing, 15(1), p.183."
  },
  {
    "objectID": "GEE.html#reference",
    "href": "GEE.html#reference",
    "title": "5  Google Earth Engine",
    "section": "5.4 Reference",
    "text": "5.4 Reference\nCrites, A. (2019) Map vs. for loop, Medium. Available at: https://medium.com/@ExplosionPills/map-vs-for-loop-2b4ce659fb03 (Accessed: 14 March 2024).\nTamiminia, H., Salehi, B., Mahdianpari, M., Quackenbush, L., Adeli, S. and Brisco, B., 2020. Google Earth Engine for geo-big data applications: A meta-analysis and systematic review. ISPRS journal of photogrammetry and remote sensing, 164, pp.152-170.\nZhao, Q., Yu, L., Li, X., Peng, D., Zhang, Y. and Gong, P., 2021. Progress and trends in the application of Google Earth and Google Earth Engine. Remote Sensing, 13(18), p.3778.\n(2023) Global Water Watch. Available at: https://www.globalwaterwatch.earth/ (Accessed: 14 March 2024)."
  },
  {
    "objectID": "Classification_I.html#summary",
    "href": "Classification_I.html#summary",
    "title": "6  Classification_I",
    "section": "6.1 Summary",
    "text": "6.1 Summary\n\n6.1.1 Terms\nLULC: Land Use & Land Cover\nLST: Land Surface Temperature\nMAP: Major Air Pollutants\nCART: Classification and Regression Trees\nRF: Random Forest\n\n\n6.1.2 How classified data could be used\n\nUrban expansion\nAir pollution\nLULC\nForest monitoring (illegal logging; forest fire)\n\n\n\n6.1.3 Machine Leaning in Remote Sensing\nThe application of machine learning in remote sensing is a kind of inductive learning, which import the knowledge from human (expert) to an algorithm system, and it could iteratively generate advice for particular problem. Essentially, the machine learning is to help making decision repeatedly. To simplify, regression could be a type of machine learning, as it can obtain the information from the fitted data, and than it can be used to make prediction based on the fitted data.\n\n\n6.1.4 CART\nThe CART comprised of classification trees and regression trees.\n\nClassification tree: Classify the data into different discrete categories (predict category)\nRegression tree: subset continuous data and do the regression separately (predict value, or value range)\n\nTo decide which variable should be used in the top of a classification tree, the Gini impurity of each variable should be calculated, and that with the lowest Gini impurity should be selected. Then, each extension of decision tree (adding the height) is to reduce the impurity of a branch. In this process, we can also compare the impurity of the rest of variables and repeat the first step.\nAs for regression tree, there is a similar impurity but it’s measured by the residual of values. We can make a plot of sum of squared residuals (SSR) verses threshold to find the threshold with the lowest SSR, then create the tree. However, since the data set of regression tree is continue and we can’t keep finding the lowest SSR in each branch, therefore, to prevent overfitting, we could set a certain number of observations that would stop the division.\n\n\n\nplot of sum of squared residuals (SSR) verses threshold, from SatQuest\n\n\n\n\n6.1.5 Random Forest\nThis algorithm could be concluded as Bagging, which means bootstrapping the data and using aggregate to make a decision (b + agg = bagging). Since a part of (about 1/3) data would be omitted in the first bagging process, those are called Out-of-Bag data, and these data would be used to test the accuracy of each tree that produced by random forest.\n\n\n6.1.6 Support Vector Machine\nThe Support Vector Machine (SVM) derives from Support Vector Classifier, which is a threshold that divide data into two categories in one-dimension. In terms of SVM, the idea is to add dimension to the data, so that a mixed up dataset can also be classified. However, in effect the data wasn’t actually transformed into a higher dimension due to computational limitation, therefore, it is using either of two kernel functions: polynomial kernel or radial kernel, to do the kernel trick. In other words, it is to use mathemmtical techniques to reduce computational complexity. (sounds confused but it’s true!)\n\n\n6.1.7 Practical result\nSince GEE allows limit elements in each FeatureCollection, I reduce to two types of landcover for the classification. The figure below demonstrates the result and accuracy, using pixel as training data and RF as the algorithm.\n\n\n\nThe result of two landcovers (low urban building and bare earth); blue refers to buildings, pink is the bare earth\n\n\n\n\n\nThe overall accuracy and consumer accuracy; 1 is low urban building, 2 is bare earth\n\n\nIn this classification, the useful result might be the classification of bare earth, because this is a kind of binary classification so the type of land cover would be either one of the two types. Therefore, those pixels that are more similar to the buildings would be classified as low urban building, though it might not actually is.\nTo improve this problem and locate the place that actually is its type, I created a third class which is used for distinguish other two classes of land cover.\n\n\n\nThe result with three types of land cover, blue refers to buildings, pink is the bare earth, and pale is grass or forest. It shows that most of area in Shenzhen are urban, mixed with some underdeveloped bare earth, and the green are mainly located in the middle of west part and the south east part.\n\n\n\n\n\nThe accuracy of three-class classification\n\n\nThe overall accuracy seems higher than the previous one, but there is an over-fitted class, which is the green area, so this is a fake high accuracy. Nevertheless, our purpose is to separate non-building and non-bare-earth area, so it is done well. The reason for over-fitting is that the area I selected for training green was the grass on the school playground, which has limit pixels. Therefore, in the train-test-split process, those pixel could not be well separated."
  },
  {
    "objectID": "Classification_I.html#application",
    "href": "Classification_I.html#application",
    "title": "6  Classification_I",
    "section": "6.2 Application",
    "text": "6.2 Application\nEssentially, the classification technique in remote sensing is to assign the land cover type to image pixels (GISGeography). There are generally three types of classifications:\n\nUnsupervised classification\nSupervised classification\nObject-Based image analysis (OBIA)\n\nThe first two is used for low spatial resolution images, and the third is used for high spatial resolution images.\nThere is no certain consensus for the best machine learning algorithm in remote sensing application, so it is likely to change the method when processing different questions (Maxwell, Warner, & Fang, 2018).\nIn practice, a balance between prediction accuracy and model interpretability should be found. Zhang & Yang (2020) suggested a feature elimination procedure which include two decision models and five variable importance measurements. Then they tested the subset feature by coastal images for the overall accuracy, indicating that the proposed algorithm has a higher overall accuracy.\n\n\n\nComparison of the thematic accuracies of land cover maps generated by the three models (Zhang & Yang, 2020)"
  },
  {
    "objectID": "Classification_I.html#section",
    "href": "Classification_I.html#section",
    "title": "6  Classification_I",
    "section": "6.3 ",
    "text": "6.3"
  },
  {
    "objectID": "Classification_I.html#reflection",
    "href": "Classification_I.html#reflection",
    "title": "6  Classification_I",
    "section": "6.4 Reflection",
    "text": "6.4 Reflection\nThe above procedure combines the idea of dimension reduction, such as PCA, to improve the accuracy of model. However, since land cover type classification seems to be a common application, I think comparing the accuracy of each land type might be more reasonable.\nBy the way, I found StatQuest is a really, really helpful channel which solve nearly all of my questions, and the author even go deeper for that to explain more clearly."
  },
  {
    "objectID": "Classification_I.html#section-1",
    "href": "Classification_I.html#section-1",
    "title": "6  Classification_I",
    "section": "6.5 ",
    "text": "6.5"
  },
  {
    "objectID": "Classification_II.html#summary",
    "href": "Classification_II.html#summary",
    "title": "7  Classification_II",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nDynamic World dataset provides nearly real time land cover data, which has 10-meter resolution (also it’s an application of GEE!). This is an example of pre-trained Earth observation dataset, which might be great when it is applied in globally land cover study. However, when it is applied on locally study, it might be not accurate enough, as more specific information may need in this case. For example, in a local study the OBIA or sub pixel analysis could be applied. This may require a shapefile of local object, i.e. buildings, or spectral information in a pixel unit, etc.\n\n7.1.1 Accuracy\nConfusion matrix, basically shows how one class may be confused for another (Wilber, 2022). This is used to record the performance of a classification. In stead of directly using overall accuracy, there are Recall and Precision that describe a typical accuracy more precisely. The Recall focus on preventing False Positive, while Precision focus on avoiding False Negative. This means, choosing which value get higher depends on the importance of the value, since sometimes we need to have a trade-off between them. For instance, if we want to make sure that the detection of one land cover, i.e. forest, is actually forest (high Precision, low False Positive), we may need to give up identifying a part of forest that may look less likely to be a forest (low Recall, high False Negative).\nTo quantify this trade-off process, we can use F1-Score to compare the overall balance of Recall and Precision. To measure and visualize the impact of the chagne of threshold, ROC plot could be helpful. Moreover, AUC could be used to compare different algorithm.\n\n\n7.1.2 Practical result\nThe figures below is the result of sub pixel analysis. I gather the endmembers by drawing polygon in the region. In the unmixing process, the figure before and after the constraint is quite different, which means the endmembers doesn’t perform well and some classes cannot be found in some pixels, which leads to negative fractions (ArcGIS).\n\n\n\nunmix, no constraint\n\n\n\n\n\nunmix, constraint\n\n\nBy comparing two constraint level, it would be found that setting the band constraint over .7 might have better performance, as it’s more similar as the sattelite image.\n\n\n\nband &gt; 0.5, blue: urban, pale: grass, green: forest, pink: bare earth\n\n\n\n\n\nconstrain &gt; 0.7"
  },
  {
    "objectID": "Classification_II.html#application",
    "href": "Classification_II.html#application",
    "title": "7  Classification_II",
    "section": "7.2 Application",
    "text": "7.2 Application\nSimple Linear Iterative Clustering (SLIC) algorithm has the advantage of processing time-constraint events. Csillik (2017) combined RF and SLIC to improve the processing speed and accuracy of pixel-level detection. The study found that the SLIC algorithm has a higher accuracy for capturing targets comparing to traditional object-based method.\nI found a review from Maxwell, Warner, & Guillen (2021), and they summarize the application of frequently used accuracy measurement among traditional RS and Deep Learning RS. They found that although some difference of accuracy measurement between them, for example, the DL RS researcher would use Intersection-over-Union (IoU) to measure the accuracy, generally it is a different expression or emphasis rather than an entirely new thing. Therefore, even though neural network makes the analyzing process hard to be understanded, in an engineering perspective, as long as the accuracy is high, it could be a better algorithm."
  },
  {
    "objectID": "Classification_II.html#section",
    "href": "Classification_II.html#section",
    "title": "7  Classification_II",
    "section": "7.3 ",
    "text": "7.3"
  },
  {
    "objectID": "Classification_II.html#reflection",
    "href": "Classification_II.html#reflection",
    "title": "7  Classification_II",
    "section": "7.4 Reflection",
    "text": "7.4 Reflection\nThe practical in this week generated lots of layers, which impressed me that there are so many way to express the information of a ground surface. Also, two continuous machine learning lectures makes me “over-fitting” — try to memorize everything! But understanding them may take more time.\nI found the accuracy measurement could be a life saver for me, since the terminologies are relatively easy to understand. Moreover, after running the classification algorithm, I can simply check the accuracy to decide whether its a good result. That’s an easy workflow! However, I believe that I should try to learn more about the knowledge of machine learning, as, well, it’s cool."
  },
  {
    "objectID": "SAR.html#summary",
    "href": "SAR.html#summary",
    "title": "8  SAR",
    "section": "8.1 Summary",
    "text": "8.1 Summary\n\n8.1.1 About Synthetic Aperture Radar (SAR)\nSAR is a type of active sensor (like the bat), and it will emit electromagnetic wave to detect the Earth surface. The signal that bounce back from surface will be captured by the sensor and be translated from electral siganl to spatial information. As the wavelength of the waves are relatively long (e.g. C-band, 7.5-3.8 cm, NASA), it is hardly influenced by weather and cloud.\nCompare to optical sensor, the SAR signal has more information, including the amplitude and wave phase.\n\n\n8.1.2 Amplitude\nThe amplitude of SAR signal would be impacted by the backscattering of ground surface. This would result in the polarization of signal due to its roughness, volume, and dielectric constant. Since the reflected signal comes from the SAR sensor itself, the polarization of signal could be measured. This means SAR sensor can capture the structure of the ground.\n\n\n\nA sketch of backscatter due to surface roughness (Jong, 2013)\n\n\n\n\n8.1.3 Phase & InSAR\nThe InSAR is to combine the detection result from two sensors, which allows it to measure the phase shift of ground. This is because the first past sensor would store the reference phase, and the second sensor will compare the new phase with the reference one. In this case, t-test might be used.\n\n\n8.1.4 Practical result\nThis practical demonstrate that SAR can detect the building structure change. By measuring the difference of surface variation before and after the explosion, and subtracting the noise, the buildings that were impacted by the explosion could be located. However, as suggested by the author, the limitation of remote sensing detection is that it could not capture the change that happen on the side of building, e.g. windows broken. This would imply that the remote sensing should be regarded as one of the monitoring and validation methods, which provides a guideline for Earth surface change. To ensure the accuracy of the information, field visit and combining with other references is neccessary.\n\n\n\nA demonstration of classification result"
  },
  {
    "objectID": "SAR.html#application",
    "href": "SAR.html#application",
    "title": "8  SAR",
    "section": "8.2 Application",
    "text": "8.2 Application\nWhile remote sensing is generally applied to environmental observation, Henderson and Xia (1997) suggested that SAR could be also used for the detection of human settlement, population, and migration. This could help increasing the frequency of population census which was taken around each five or ten years.\nIn effect, though SAR signal can theoretically penetrate clouds, it would still influenced by the atmosphere due to the backscatter, in which scatters would interfere with each other. Therefore, finding constant factor within variation can mitigate the impact of the atmoshpere. Perissin and Wang (2010) verified the time-series InSAR application in China, involving the the application of PS-InSAR (wha’s that?).\nAddition to remote sensing, SAR could be also applied to tactical class UAV for mission planning (Stecz & Gromada, 2020)."
  },
  {
    "objectID": "SAR.html#section",
    "href": "SAR.html#section",
    "title": "8  SAR",
    "section": "8.3 ",
    "text": "8.3"
  },
  {
    "objectID": "SAR.html#reflection",
    "href": "SAR.html#reflection",
    "title": "8  SAR",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection\nThe working principle of SAR reminds me of Bootstrap in data processing. Since the physical area that SAR sensor could detect in certain time is limit, it repeatly samples the region many times, which capture a larger amount of data than it actually has."
  },
  {
    "objectID": "intro.html#section",
    "href": "intro.html#section",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.2 ",
    "text": "1.2 \n\n1.2.1 Practical Result\nFor the practical, I selected five points for analysis:\n\n\n\nYellow: bare plane; green: forest; red: lower urban; pink: higher urban; brown (a small dot to the right in the middle): grass\n\n\nThe spectral signatures could be generated by selecting point of interested in the map, and it could be plotted by R. The figures below show the line graph of bands:\n\n\n\n\n\nThe bands have been renamed, and the wavelength of each band should be checked (see here). As every landscape has its own spectral signature, it could be used to determine the components within the POI. However, due to limit resolution and number of points, this result might not quite precise to detect the landscapes. For example, the variance of high_urban area is large, which means it contain other components addition to buildings."
  },
  {
    "objectID": "Week_3.html#section",
    "href": "Week_3.html#section",
    "title": "3  Data Enhancement",
    "section": "3.2 ",
    "text": "3.2 \n\n3.2.1 Data Pre-process\nA problem of remote sensing data is that the area of one image may not cover the entire study area, as the satellites are moving relative to the ground and scan the land square by square. The date of different data square would be varied. Therefore, to obtain the ground information of whole study area, the data should be accessed over a period of time. Then, the images should be merged together to form the targeted area.\nThe quality of remote sensing data are tired, which would be checked in here.\nIn this study, the ground information of Cape Town would be explored.\n\n\n\nA screen shot on USGS website when capturing the data in Cape Town\n\n\nAs shown in the figure, two square of remote sensing data would be used. There is an overlapped area between the two data set, and it should be eliminated in the merging process (called Mosaicking in remote sensing). The merging process is basically calculate the average value from different data square for the overlapped area. As the study area may not precisely locate within the square in the selected time period, this is a compromise for the provided data.\n\n\n3.2.2 Information Enhancement\nThe remote sensing data contains lots of information, selecting and combining those information is important for study what we focus on. Using Normalised Difference Vegetation Index (NDVI) as an example to show how the combination of bands could generate useful information.\nThe equation of NDVI is: NDVI = (NIR - Red) / (NIR + Red)\nIn Landsat data set, it is: NDVI = (B5 - B4) / (B5 + B4)\n\n\n\nThe result of NVDI plot in the targeted region\n\n\nThe value of NVDI indicate the component or state of the plants. If the NVDI &gt; 0.2, it represents the area with leaf; if the NVDI &gt; 0.6, it represents healthier leaf.\n\n\n\n\n\nAccording to the division, the leaf condition could be detected in Cape Town:\n\n\n\nNVDI &gt; 0.2\n\n\n\n\n\nNVDI &gt; 0.6\n\n\nThe figures show that few health leaf in the Cape Town, probably because the time period of the data is around May, when it’s close to winter in the Southern Hemisphere."
  },
  {
    "objectID": "SAR.html#reference",
    "href": "SAR.html#reference",
    "title": "8  SAR",
    "section": "8.4 Reference",
    "text": "8.4 Reference\nDe Jong, J.T., 2013. Recent changes in glacier facies zonation on Devon Ice Cap, Nunavut, detected from SAR imagery and field validation methods. University of Ottawa (Canada).\nHenderson, F.M. and Xia, Z.G., 1997. SAR applications in human settlement detection, population estimation and urban land use pattern analysis: a status report. IEEE transactions on geoscience and remote sensing, 35(1), pp.79-85.\nPerissin, D. and Wang, T., 2010. Time-series InSAR applications over urban areas in China. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 4(1), pp.92-100.\nStecz, W. and Gromada, K., 2020. UAV mission planning with SAR application. Sensors, 20(4), p.1080."
  },
  {
    "objectID": "Week_2.html#section",
    "href": "Week_2.html#section",
    "title": "2  The Xaringan Slides",
    "section": "2.1 ",
    "text": "2.1"
  },
  {
    "objectID": "Classification_I.html#reference",
    "href": "Classification_I.html#reference",
    "title": "6  Classification_I",
    "section": "6.5 Reference",
    "text": "6.5 Reference\nGISGeography (2024) Image classification techniques in remote sensing, GIS Geography. Available at: https://gisgeography.com/image-classification-techniques-remote-sensing/ (Accessed: 22 March 2024).\nMaxwell, A.E., Warner, T.A. and Fang, F., 2018. Implementation of machine-learning classification in remote sensing: An applied review. International journal of remote sensing, 39(9), pp.2784-2817.\nZhang, F. and Yang, X., 2020. Improving land cover classification in an urbanized coastal area by random forests: The role of variable selection. Remote Sensing of Environment, 251, p.112105."
  },
  {
    "objectID": "Classification_II.html#reference",
    "href": "Classification_II.html#reference",
    "title": "7  Classification_II",
    "section": "7.5 Reference",
    "text": "7.5 Reference\nCsillik, O., 2017. Fast segmentation and classification of very high resolution remote sensing data using SLIC superpixels. Remote Sensing, 9(3), p.243.\nDynamic World - 10M Global Land Cover Dataset in Google Earth engine (no date) Dynamic World - 10m global land cover dataset in Google Earth Engine. Available at: https://www.dynamicworld.app/explore/ (Accessed: 22 March 2024).\nLinear spectral unmixing function (no date) Linear Spectral Unmixing function-ArcGIS Online | Documentation. Available at: https://doc.arcgis.com/en/arcgis-online/analyze/linear-spectral-unmixing.htm (Accessed: 22 March 2024).\nMaxwell, A.E., Warner, T.A. and Guillén, L.A., 2021. Accuracy assessment in convolutional neural network-based deep learning remote sensing studies—Part 1: Literature review. Remote Sensing, 13(13), p.2450.\nWilber, J. (no date) Precision and recall, MLU. Available at: https://mlu-explain.github.io/precision-recall/ (Accessed: 22 March 2024)."
  },
  {
    "objectID": "intro.html#reference",
    "href": "intro.html#reference",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.4 Reference",
    "text": "1.4 Reference\nNavalgund, R.R., Jayaraman, V. and Roy, P.S., 2007. Remote sensing applications: An overview. current science, pp.1747-1766.\nRathore, M.M.U., Paul, A., Ahmad, A., Chen, B.W., Huang, B. and Ji, W., 2015. Real-time big data analytical architecture for remote sensing application. IEEE journal of selected topics in applied earth observations and remote sensing, 8(10), pp.4610-4621.\nWójtowicz, M., Wójtowicz, A. and Piekarczyk, J., 2016. Application of remote sensing methods in agriculture. Communications in biometry and crop science, 11(1), pp.31-50.\nYao, H., Qin, R. and Chen, X., 2019. Unmanned aerial vehicle for remote sensing applications—A review. Remote Sensing, 11(12), p.1443."
  },
  {
    "objectID": "intro.html#navalgund-r.r.-jayaraman-v.-and-roy-p.s.-2007.-remote-sensing-applications-an-overview.-current-science-pp.1747-1766.",
    "href": "intro.html#navalgund-r.r.-jayaraman-v.-and-roy-p.s.-2007.-remote-sensing-applications-an-overview.-current-science-pp.1747-1766.",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.5 Navalgund, R.R., Jayaraman, V. and Roy, P.S., 2007. Remote sensing applications: An overview. current science, pp.1747-1766.",
    "text": "1.5 Navalgund, R.R., Jayaraman, V. and Roy, P.S., 2007. Remote sensing applications: An overview. current science, pp.1747-1766.\nRathore, M.M.U., Paul, A., Ahmad, A., Chen, B.W., Huang, B. and Ji, W., 2015. Real-time big data analytical architecture for remote sensing application. IEEE journal of selected topics in applied earth observations and remote sensing, 8(10), pp.4610-4621.\nWójtowicz, M., Wójtowicz, A. and Piekarczyk, J., 2016. Application of remote sensing methods in agriculture. Communications in biometry and crop science, 11(1), pp.31-50.\nYao, H., Qin, R. and Chen, X., 2019. Unmanned aerial vehicle for remote sensing applications—A review. Remote Sensing, 11(12), p.1443."
  },
  {
    "objectID": "Week_3.html#reference",
    "href": "Week_3.html#reference",
    "title": "3  Data Enhancement",
    "section": "3.4 Reference",
    "text": "3.4 Reference\nUddin, M.P., Mamun, M.A. and Hossain, M.A., 2021. PCA-based feature reduction for hyperspectral remote sensing image classification. IETE Technical Review, 38(4), pp.377-396."
  }
]