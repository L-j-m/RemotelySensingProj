[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning Diary of CASA0023 Remotely Sensing Cities and Environments 23/24",
    "section": "",
    "text": "Introduction\nHi, my name is Jiaming Li. During my undergraduate study, I was major in Architectural Environment Engineering. Basically it was being an engineer to design the heating and cooling system for a building. We did a lot of energy simulation for buildings, which aimed to further modify the building system to reduce its energy consumption while ensuring its performance.\nIn my current study in Urban Spatial Science course, I found a different perspective to interpret buildings. Now we can see building in a higher level, in which the group of buildings form a city. Therefore, I can improve my understanding on building as a role within an urban area."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Week 1",
    "section": "",
    "text": "Terms\n\nNIR (Near-infrared, which is used to detect vegetation)"
  },
  {
    "objectID": "Week_2.html#week_2",
    "href": "Week_2.html#week_2",
    "title": "2  Week_2",
    "section": "2.1 Week_2",
    "text": "2.1 Week_2"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Week_2.html#week-2",
    "href": "Week_2.html#week-2",
    "title": "2  Week 2",
    "section": "2.1 Week 2",
    "text": "2.1 Week 2"
  },
  {
    "objectID": "Week_3.html",
    "href": "Week_3.html",
    "title": "3  Week 3",
    "section": "",
    "text": "4 Week 3"
  },
  {
    "objectID": "Week_2.html#the-xaringan-presentation",
    "href": "Week_2.html#the-xaringan-presentation",
    "title": "2  Week 2",
    "section": "2.1 The Xaringan presentation",
    "text": "2.1 The Xaringan presentation"
  },
  {
    "objectID": "Week_3.html#corrections",
    "href": "Week_3.html#corrections",
    "title": "3  Week 3",
    "section": "3.1 Corrections",
    "text": "3.1 Corrections\nThere are four types of corrections:\n\nGeometric correction\nAtmospheric correction\nOrthorectification / Topographic correction\nRadiometric correction"
  },
  {
    "objectID": "Week_3.html#terms",
    "href": "Week_3.html#terms",
    "title": "3  Week 3",
    "section": "Terms",
    "text": "Terms\n\n.MTL file: store the data of Earth-sun distance.\nNDVI (Normalised Difference Vegetation Index).\nNDMI (Normalized Difference Moisture Index)."
  },
  {
    "objectID": "Week_3.html#data-enhancement",
    "href": "Week_3.html#data-enhancement",
    "title": "3  Week 3",
    "section": "3.2 Data enhancement",
    "text": "3.2 Data enhancement\nTasseled Cap function -&gt; Principal Component Analysis (PCA)\nThe PCA is a process that transform the data which has reduced its dimensionality. This is to highlight certain feature of an image.\n\n3.2.1"
  },
  {
    "objectID": "intro.html#remote-sensing-data",
    "href": "intro.html#remote-sensing-data",
    "title": "1  Week 1",
    "section": "1.1 Remote sensing data",
    "text": "1.1 Remote sensing data\n\nSentinel:\nCollected by European Space Agency (ESA)\nLandsat\nCollected by United States Geological Survey (USGS) and NASA.\n\nWhen doing the comparison of Sentinel and Landsat dataset, the image from Sentinel should be upscaled as the resolution of Sentinel RGB bands are 10 meter while the RGB bands from Landsat are 30 meter. When looking at the natural colors of images, we’ll use B2, B3, and B4 in blue, green, and red pipes, therefore, the those bands should be upscaled from 10 meter to 30 meter.\nThe color of an image is formed by electromegnetic, or, it is a representation of information of targets on the Earth surface. In this case, how electromegnetic is expressed by color would be essential to understand the targets on the Earth surface, and we can change the math expression of the bands to make the color have different meaning.\nThe component of target within a pixel can be analyzed from Spectrum View, in which x axis is the Wavelength (nm) of bands, y axis is the percentage of reflectance (?). The table below shows the wavelength of each band:\n\n\n\nBand\nWavelength (nm)\nDescription\n\n\n\n\nB1\n443\nUltra Blue (Coastal and Aerosol)\n\n\nB2\n490\nBlue\n\n\nB3\n560\nGreen\n\n\nB4\n665\nRed\n\n\nB5 - B8, B8a\n705 - 865\nVisible & Near Infrared (VNIR)\n\n\nB9 - B12\n940 - 2190\nShort Wave Infrared (SWIR)"
  },
  {
    "objectID": "Week_2.html#reflection",
    "href": "Week_2.html#reflection",
    "title": "2  Week 2",
    "section": "2.2 Reflection",
    "text": "2.2 Reflection"
  },
  {
    "objectID": "intro.html#summary",
    "href": "intro.html#summary",
    "title": "1  Week 1 Introduction to Remote Sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\nRemote sensing, or called Earth Observation (EO), refers to obtain information from a distance. Generally, satellites or drones are typical remote sensors, which are used to acquiring data of Earth ground.\nAn advantage of remote sensing data is that it has large amount of data size, which update frequently (around every day to every 16 days). Therefore, it would be suitable for timely analysis the variation of city or building, and they could be observed in a longer time (years or decades).\n\n1.1.1 Remote sensing data\n\nSentinel:\nCollected by European Space Agency (ESA)\nLandsat\nCollected by United States Geological Survey (USGS) and NASA.\n\nFormat: generally raster.\nResolutions: spatial (pixels), spectral (bands), temporal (days, years), radiometric (the ability of detecting the radiation difference. unit: 8 bit, 11 bit).\nThe sensor detecting Earth ground relies on electromagnetic radiation, and a key character of it is the wavelength (λ). It would determine the ability of sensors that penetrate through clouds or ground layers. For instance, for longer wavelength, they are less likely to be scattered by clouds, thus they’re more likely to obtain data in a cloudy weather.\nIn terms of the data, generally they are images. The color of an image data is formed by electromagnetic, or, it is a representation of information of targets on the Earth surface. In this case, how electromagnetic is expressed by color would be essential to understand the targets on the Earth surface, and we can change the math expression of the bands to make the color have different meaning.\n\n\n1.1.2 Interacting with ground surface\n\nBidirectional Reflectance Distribution Function (BRDF): It’s a function that describes the ratio of the reflectance light that viewer could receive and the source of light that illuminates the object.\n\n\n\n\nSchematic plot of reflectance, the amount of reflected light would be less or equal to the incoming light (Wynn, 2000)\n\n\nThe two types below is more about SAR data.\n\nPolarization: This refers to the deflection of signals. There are two plane of electromagnetic signal: horizontal and vertical. When the signal is polarized, the direction of electromagnetic oscillation may change.\nFluoresence: The wavelength of radiation would change after arriving the target."
  },
  {
    "objectID": "intro.html#application",
    "href": "intro.html#application",
    "title": "1  Week 1 Introduction to Remote Sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\n\n1.2.1 Result of Practical 1\nFor the practical, I selected five points for analysis:\n\n\n\nYellow: bare plane; green: forest; red: lower urban; pink: higher urban; brown (a small dot to the right in the middle): grass\n\n\nThe spectral signatures could be generated by selecting point of interested in the map, and it could be plotted by R. The figures below show the line graph of bands:\n\n\n\n\n\nThe bands have been renamed, and the wavelength of each band should be checked (see here). As every landscape has its own spectral signature, it could be used to determine the components within the POI. However, due to limit resolution and number of points, this result might not quite precise to detect the landscapes. For example, the variance of high_urban area is large, which means it contain other components addition to buildings."
  },
  {
    "objectID": "intro.html#reflection",
    "href": "intro.html#reflection",
    "title": "1  Week 1 Introduction to Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nIn this week, the basic knowledge frame of remote sensing was introduced. What I found interested was the way that remote sensor works. Before, I though the sensors would work as camera, which capture information by taking picture. But in effect, the electromagnetic that emit and receive by the sensors is actually important. It is the bands that make up the message. Especially, in terms of the application of SAR sensors, it could largely ignore the weather condition, and constantly observing the Earth ground.\nSome terms that might be useful:\n\nNIR (Near-infrared, which is used to detect vegetation)\n\n\n1.3.1 Notes\nWhen doing the comparison of Sentinel and Landsat data set, the image from Sentinel should be up-scaled as the resolution of Sentinel RGB bands are 10 meter while the RGB bands from Landsat are 30 meter. When looking at the natural colors of images, we’ll use B2, B3, and B4 in blue, green, and red pipes, therefore, the those bands should be up-scaled from 10 meter to 30 meter.\nThe component of target within a pixel can be analyzed from Spectrum View (in SNAP), in which x axis is the Wavelength (nm) of bands, y axis is the percentage of reflectance."
  },
  {
    "objectID": "Week_3.html#summary",
    "href": "Week_3.html#summary",
    "title": "3  Week 3",
    "section": "3.1 Summary",
    "text": "3.1 Summary\nThe process of remote sensing based on three essential components: light sources (illuminentes), target (Earth ground), and sensors. The light source could be the same as the sensors (active sensor, SAR).\nTo store the information of targets, the radiance would be “translated” into the Digital Number (DN), which is the raw data of ground information. Those raw data would be combined with theirs location, and then it could form the map. (source: OpenLibrary)\n\n3.1.1 Radiance & Reflectance\nThe radiance is used to describe the light that received by sensors, while reflectance relates to the properties of the targets.\n\nRadiance: how much light the sensor can receive (the radiation leaving the Earth).\nReflectance: the ratio of light leaving a target to the light striking the target.\n\nBOA (Bottom of Atmosphere) reflectance: reflected by the target on Earth surface.\nTOA (Top of Atmosphere) reflectance: regard atm as the target, can be converted from TOA radiance (path radiance).\n\n\n\n\n3.1.2 Correction\nThe accuracy of remote sensing data may have its limit due to several reasons, such as the relative position between satellites and ground (view angle), atmospheric scattering, property of instruments. Therefore, we need to do the corrections before analyzing the data.\nThere are four types of corrections:\n\nGeometric correction\nAtmospheric correction\nOrthorectification / Topographic correction\nRadiometric correction\n\nA useful atmospheric correction called Dark Object Subtraction (DOS). The basic assumption in the algorithm is that the darkest pixel in the image should not have any light. Thus, any reflectance from this pixel should caused by the atmospheric. As those light doesn’t achieve the ground but being reflected to the sensors. Therefore, all pixel should subtract this impact.\n\n\n3.1.3 Data enhancement\nTasseled Cap function -&gt; Principal Component Analysis (PCA)\nThe PCA is a process that transform the data which has reduced its dimensionality. This is to highlight certain feature of an image."
  },
  {
    "objectID": "Week_3.html#application",
    "href": "Week_3.html#application",
    "title": "3  Week 3",
    "section": "3.2 Application",
    "text": "3.2 Application\n\n3.2.1 Data Pre-process\nA problem of remote sensing data is that the area of one image may not cover the entire study area, as the satellites are moving relative to the ground and scan the land square by square. The date of different data square would be varied. Therefore, to obtain the ground information of whole study area, the data should be accessed over a period of time. Then, the images should be merged together to form the targeted area.\nThe quality of remote sensing data are tired, which would be checked in here.\nIn this study, the ground information of Cape Town would be explored.\n\n\n\nA screen shot on USGS website when capturing the data in Cape Town\n\n\nAs shown in the figure, two square of remote sensing data would be used. There is an overlapped area between the two data set, and it should be eliminated in the merging process (called Mosaicking in remote sensing). The merging process is basically calculate the average value from different data square for the overlapped area. As the study area may not precisely locate within the square in the selected time period, this is a compromise for the provided data.\n\n\n3.2.2 Information Enhancement\nThe remote sensing data contains lots of information, selecting and combining those information is important for study what we focus on. Using Normalised Difference Vegetation Index (NDVI) as an example to show how the combination of bands could generate useful information.\nThe equation of NDVI is: NDVI = (NIR - Red) / (NIR + Red)\nIn Landsat data set, it is: NDVI = (B5 - B4) / (B5 + B4)\n\n\n\nThe result of NVDI plot in the targeted region\n\n\nThe value of NVDI indicate the component or state of the plants. If the NVDI &gt; 0.2, it represents the area with leaf; if the NVDI &gt; 0.6, it represents healthier leaf.\n\n\n\n\n\nAccording to the division, the leaf condition could be detected in Cape Town:\n\n\n\nNVDI &gt; 0.2\n\n\n\n\n\nNVDI &gt; 0.6\n\n\nThe figures show that few health leaf in the Cape Town, probably because the time period of the data is around May, when it’s close to winter in the Southern Hemisphere."
  },
  {
    "objectID": "Week_3.html#reflection",
    "href": "Week_3.html#reflection",
    "title": "3  Week 3",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nThere are other ways to process and enhance the remote sensing data, and substantially they are used to reduce the amount of data.\nFor example, using moving windows to filter the data, essentially, it’s to increase the contrast of the image while reducing the noise pixels.\nComparing to directly process the data, Principle Component Analysis (PCA) is a more advanced, or abstract technique that replace the variables by their correlations. Then, using the variation in each fitting line, it could calculate the importance of each correlation. Essentially, PCA could be used to reduce the dimension of data. I found Kim (2022) explained the PCA very well. He suggested that the process of PCA likes an orthorectification correction, and those dimensions in which data has not variation should be filtered out.\n\n\n\nThe data has few variation in Z axis, therefore, Z dimension could be subtracted\n\n\n\n3.3.1 Reference\n\n\n3.3.2"
  }
]